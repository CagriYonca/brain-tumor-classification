{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9 no.jpg', '6 no.jpg', '17 no.jpg', '2 no.jpg', '23 no.jpg', '24 no.jpg', '12 no.jpg', '15 no.jpg', '4 no.jpg', '11 no.jpg', '18 no.jpg', '20 no.jpg', '22 no.jpg', '19 no.jpg', '13 no.jpg', '14 no.jpg', '7 no.jpg', '5 no.jpg', '222 no.jpg', '1 no.jpg', '10 no.jpg', '111 no.jpg', '21 no.jpg', '8 no.jpg']\n",
      "9 no.jpg\n",
      "6 no.jpg\n",
      "17 no.jpg\n",
      "2 no.jpg\n",
      "23 no.jpg\n",
      "24 no.jpg\n",
      "12 no.jpg\n",
      "15 no.jpg\n",
      "4 no.jpg\n",
      "11 no.jpg\n",
      "18 no.jpg\n",
      "20 no.jpg\n",
      "22 no.jpg\n",
      "19 no.jpg\n",
      "13 no.jpg\n",
      "14 no.jpg\n",
      "7 no.jpg\n",
      "5 no.jpg\n",
      "222 no.jpg\n",
      "1 no.jpg\n",
      "10 no.jpg\n",
      "111 no.jpg\n",
      "21 no.jpg\n",
      "8 no.jpg\n"
     ]
    }
   ],
   "source": [
    "# Preprocess images\n",
    "path = \"/home/user/workspace3/Dataset/Test/A/\"\n",
    "\n",
    "dirs = os.listdir(path)\n",
    "print(dirs)\n",
    "def resize():\n",
    "    for item in dirs:\n",
    "        if os.path.isfile(path + item):\n",
    "            print(item)\n",
    "            im = Image.open(path+item).convert('L')\n",
    "            f, e = os.path.splitext(path + item)\n",
    "            imResize = im.resize((28, 28), Image.ANTIALIAS)\n",
    "            imResize.save(f + \".jpg\", 'JPEG', quality=90)\n",
    "            if(os.path.isfile(f)):\n",
    "                os.remove(f)\n",
    "            if(os.path.isfile(f + \".JPG\")):\n",
    "                os.remove(f + \".JPG\")\n",
    "resize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "%matplotlib inline\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from imageio import imread\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class notMNIST(Dataset):\n",
    "\n",
    "    # The init method is called when this class will be instantiated.\n",
    "    def __init__(self, root):\n",
    "        Images, Y = [], []\n",
    "        folders = os.listdir(root)\n",
    "\n",
    "        for folder in folders:\n",
    "            folder_path = os.path.join(root, folder)\n",
    "            for ims in os.listdir(folder_path):\n",
    "                try:\n",
    "                    img_path = os.path.join(folder_path, ims)\n",
    "                    Images.append(np.array(imread(img_path)))\n",
    "                    Y.append(ord(folder) - 65)\n",
    "                except:\n",
    "                    # Some images in the dataset are damaged\n",
    "                    print(\"File {}/{} is broken\".format(folder, ims))\n",
    "        data = [(x, y) for x, y in zip(Images, Y)]\n",
    "        self.data = data\n",
    "\n",
    "    # The number of items in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # The Dataloader is a generator that repeatedly calls the getitem method.\n",
    "    # getitem is supposed to return (X, Y) for the specified index.\n",
    "    def __getitem__(self, index):\n",
    "        img = self.data[index][0]\n",
    "        img = img.reshape(28, 28) / 255.0\n",
    "        # 8 bit images. Scale between [0,1]. This helps speed up our training\n",
    "        # img = img.reshape(28, 28) / 255.0\n",
    "\n",
    "        # Input for Conv2D should be Channels x Height x Width\n",
    "        img_tensor = Tensor(img).view(1, 28, 28).float()\n",
    "        label = self.data[index][1]\n",
    "        return (img_tensor, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "\n",
    "        # Reshaping the tensor to BATCH_SIZE x 320. Torch infers this from other dimensions when one of the parameter is -1.\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "MODEL_NAME = 'conv2_layer_28x28'\n",
    "BATCH_SIZE = 4\n",
    "N_EPOCHS = 50\n",
    "root = \"/home/user/workspace3\"\n",
    "\n",
    "# Load data\n",
    "train_dataset = notMNIST(os.path.join(root, 'Dataset/Train'))\n",
    "\n",
    "# Create dataloader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Create model\n",
    "net = Model()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    epoch_loss = 0\n",
    "    n_batches = len(train_dataset) // BATCH_SIZE\n",
    "\n",
    "    for step, data in enumerate(train_loader, 0):\n",
    "        train_x, train_y = data\n",
    "        y_hat = net.forward(train_x)\n",
    "        train_y = torch.Tensor(np.array(train_y))\n",
    "\n",
    "        # CrossEntropyLoss requires arg2 to be torch.LongTensor\n",
    "        loss = criterion(y_hat, train_y.long())\n",
    "        epoch_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # There are len(dataset)/BATCH_SIZE batches.\n",
    "        # We print the epoch loss when we reach the last batch.\n",
    "        if step % n_batches == 0 and step != 0:\n",
    "            epoch_loss = epoch_loss / n_batches\n",
    "            loss_history.append(epoch_loss)\n",
    "            print(\"Epoch {}, loss {}\".format(epoch, epoch_loss))\n",
    "            epoch_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model...\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    train(epoch)\n",
    "\n",
    "# Saving the model\n",
    "torch.save(net, 'models/{}.pt'.format(MODEL_NAME))\n",
    "print(\"Saved model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.8409090909090909\n"
     ]
    }
   ],
   "source": [
    "test_dataset = notMNIST(os.path.join(root, 'Dataset/Test'))\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "classifier = torch.load('models/{}.pt'.format(MODEL_NAME)).eval()\n",
    "correct = 0\n",
    "\n",
    "for _, data in enumerate(test_loader, 0):\n",
    "    test_x, test_y = data\n",
    "    pred = classifier.forward(test_x)\n",
    "    y_hat = np.argmax(pred.data)\n",
    "    if y_hat == test_y:\n",
    "        correct += 1\n",
    "\n",
    "print(\"Accuracy={}\".format(correct / len(test_dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
